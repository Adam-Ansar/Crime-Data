{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Gun Crime analysis**\n",
        "\n",
        "Hypothethis: Hypothesis 1: Suicide rates are higher among individuals with lower educational attainment.\n",
        "\n",
        "Rationale: Socioeconomic factors, including education level, are often correlated with mental health and access to resources. Lower education may indicate increased stress and limited opportunities, potentially contributing to higher suicide rates.\n",
        "\n",
        "Analysis: You could compare the suicide rates across different education levels. Calculate the percentage of gun deaths that are suicides for each education category (e.g., \"Less than HS\", \"HS/GED\", \"BA+\"). Use statistical tests (e.g., chi-squared test) to see if the differences are statistically significant."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "1. **Load the Dataset**: Import the necessary CSV files into dataframes.\n",
        "2. **Explore the Data**: Perform initial exploration to understand the structure and content of the data.\n",
        "3. **Data Cleaning and Refinement**: Clean the data by handling missing values, correcting data types, and refining the dataset for analysis.\n",
        "4. **Surface Level Analysis**: Conduct preliminary analysis to identify trends, patterns, and key statistics.\n",
        "5. **Basic Visualizations**: Create visual representations of the data to aid in understanding and communicating findings.\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* \n",
        "## Outputs\n",
        "\n",
        "* \n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "* \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'c:\\\\Users\\\\Compu\\\\Crime-Data\\\\jupyter_notebooks'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You set a new current directory\n"
          ]
        }
      ],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'c:\\\\Users\\\\Compu\\\\Crime-Data'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File exists\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Check if the file exists in the current directory\n",
        "file_path = os.path.join(current_dir, 'gun_deaths.csv')\n",
        "if os.path.exists(file_path):\n",
        "    print(\"File exists\")\n",
        "else:\n",
        "    print(\"File does not exist\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Section 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Exploration, Cleaning, and Refinement\n",
        "\n",
        "### Data Exploration\n",
        "Data exploration involves examining the dataset to understand its structure, content, and key characteristics. This step includes:\n",
        "1. **Loading the Dataset**: Importing the dataset into a DataFrame.\n",
        "2. **Initial Exploration**: Displaying the first few rows to get a sense of the data.\n",
        "3. **Summary Statistics**: Using methods like `info()` and `describe()` to get an overview of the dataset, including data types, missing values, and basic statistical measures.\n",
        "4. **Identifying Missing Values**: Checking for missing values in the dataset, which can affect analysis and need to be addressed.\n",
        "5. **Identifying Duplicate Rows**: Checking for duplicate rows that can inflate the dataset and skew analysis results.\n",
        "\n",
        "### Data Cleaning\n",
        "Data cleaning involves handling issues identified during exploration to ensure the dataset is accurate and reliable. This step includes:\n",
        "1. **Handling Missing Values**: Addressing missing values by either filling them with appropriate values (e.g., mean, median) or removing rows/columns with excessive missing data.\n",
        "2. **Removing Duplicate Rows**: Dropping duplicate rows to ensure each entry in the dataset is unique.\n",
        "3. **Correcting Data Types**: Ensuring that each column has the correct data type (e.g., converting columns to categorical or numerical types as needed).\n",
        "\n",
        "### Data Refinement\n",
        "Data refinement involves further processing the cleaned dataset to prepare it for analysis. This step includes:\n",
        "1. **Feature Engineering**: Creating new features or modifying existing ones to enhance the dataset's predictive power.\n",
        "2. **Normalization and Scaling**: Normalizing or scaling numerical features to ensure they are on a similar scale, which can improve the performance of certain algorithms.\n",
        "3. **Encoding Categorical Variables**: Converting categorical variables into numerical format using techniques like one-hot encoding or label encoding.\n",
        "\n",
        "By following these steps, we ensure that the dataset is well-prepared for meaningful analysis and visualization, leading to more accurate and insightful results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Importing the required libraries\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import scipy.stats as stats\n",
        "import statsmodels.api as sm\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Importing the required libraries is essential and the foundation of any data analysis of a dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>intent</th>\n",
              "      <th>police</th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>race</th>\n",
              "      <th>place</th>\n",
              "      <th>education</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2012</td>\n",
              "      <td>1</td>\n",
              "      <td>Suicide</td>\n",
              "      <td>0</td>\n",
              "      <td>M</td>\n",
              "      <td>34.0</td>\n",
              "      <td>Asian/Pacific Islander</td>\n",
              "      <td>Home</td>\n",
              "      <td>BA+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2012</td>\n",
              "      <td>1</td>\n",
              "      <td>Suicide</td>\n",
              "      <td>0</td>\n",
              "      <td>F</td>\n",
              "      <td>21.0</td>\n",
              "      <td>White</td>\n",
              "      <td>Street</td>\n",
              "      <td>Some college</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2012</td>\n",
              "      <td>1</td>\n",
              "      <td>Suicide</td>\n",
              "      <td>0</td>\n",
              "      <td>M</td>\n",
              "      <td>60.0</td>\n",
              "      <td>White</td>\n",
              "      <td>Other specified</td>\n",
              "      <td>BA+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>Suicide</td>\n",
              "      <td>0</td>\n",
              "      <td>M</td>\n",
              "      <td>64.0</td>\n",
              "      <td>White</td>\n",
              "      <td>Home</td>\n",
              "      <td>BA+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>Suicide</td>\n",
              "      <td>0</td>\n",
              "      <td>M</td>\n",
              "      <td>31.0</td>\n",
              "      <td>White</td>\n",
              "      <td>Other specified</td>\n",
              "      <td>HS/GED</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   year  month   intent  police sex   age                    race  \\\n",
              "0  2012      1  Suicide       0   M  34.0  Asian/Pacific Islander   \n",
              "1  2012      1  Suicide       0   F  21.0                   White   \n",
              "2  2012      1  Suicide       0   M  60.0                   White   \n",
              "3  2012      2  Suicide       0   M  64.0                   White   \n",
              "4  2012      2  Suicide       0   M  31.0                   White   \n",
              "\n",
              "             place     education  \n",
              "0             Home           BA+  \n",
              "1           Street  Some college  \n",
              "2  Other specified           BA+  \n",
              "3             Home           BA+  \n",
              "4  Other specified        HS/GED  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load the dataset\n",
        "data = pd.read_csv('gun_deaths.csv')\n",
        "\n",
        "# Display the first 5 rows of the dataset\n",
        "data.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```markdown\n",
        "# Initial Exploration of the Dataset\n",
        "\n",
        "The first five rows of the dataset provide a snapshot of the data structure and content. Here are some key observations:\n",
        "\n",
        "1. **Columns**:\n",
        "    - `year`: The year in which the incident occurred.\n",
        "    - `month`: The month in which the incident occurred.\n",
        "    - `intent`: The intent behind the incident (e.g., Suicide, Homicide).\n",
        "    - `police`: Indicates whether a police officer was involved (0 for no, 1 for yes).\n",
        "    - `sex`: The gender of the victim (M for male, F for female).\n",
        "    - `age`: The age of the victim.\n",
        "    - `race`: The race of the victim.\n",
        "    - `place`: The location where the incident occurred.\n",
        "    - `education`: The education level of the victim.\n",
        "\n",
        "2. **Data Types**:\n",
        "    - The `year`, `month`, and `police` columns are of integer type.\n",
        "    - The `age` column is of float type, indicating that it may contain missing values.\n",
        "    - The `intent`, `sex`, `race`, `place`, and `education` columns are of object type, representing categorical data.\n",
        "\n",
        "3. **Missing Values**:\n",
        "    - The `intent` column has 1 missing value.\n",
        "    - The `age` column has 18 missing values.\n",
        "    - The `place` column has 1,384 missing values.\n",
        "    - The `education` column has 1,422 missing values.\n",
        "\n",
        "4. **Duplicate Rows**:\n",
        "    - There are 39,227 duplicate rows in the dataset, which need to be addressed during data cleaning.\n",
        "\n",
        "5. **Distribution of Education Levels**:\n",
        "    - The dataset contains various education levels, with `HS/GED` being the most common, followed by `Less than HS`, `Some college`, and `BA+`. There are also 1,422 missing values in the `education` column.\n",
        "\n",
        "These initial findings highlight the need for data cleaning and refinement to handle missing values, remove duplicate rows, and ensure accurate data types for meaningful analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100798 entries, 0 to 100797\n",
            "Data columns (total 9 columns):\n",
            " #   Column     Non-Null Count   Dtype  \n",
            "---  ------     --------------   -----  \n",
            " 0   year       100798 non-null  int64  \n",
            " 1   month      100798 non-null  int64  \n",
            " 2   intent     100797 non-null  object \n",
            " 3   police     100798 non-null  int64  \n",
            " 4   sex        100798 non-null  object \n",
            " 5   age        100780 non-null  float64\n",
            " 6   race       100798 non-null  object \n",
            " 7   place      99414 non-null   object \n",
            " 8   education  99376 non-null   object \n",
            "dtypes: float64(1), int64(3), object(5)\n",
            "memory usage: 6.9+ MB\n"
          ]
        }
      ],
      "source": [
        "# Get a summary of the dataset\n",
        "data.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```markdown\n",
        "The `data.info()` method provides a concise summary of the DataFrame, which includes the number of entries (rows), the number of columns, and the data types of each column. It also shows the non-null count for each column, indicating how many non-missing values are present. This summary helps in understanding the structure of the dataset, identifying columns with missing values, and verifying the data types of each column. For instance, in our dataset, we have 100,798 entries and 9 columns, with some columns containing missing values (e.g., 'intent', 'age', 'place', and 'education'). The data types include integers, floats, and objects (categorical data).\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>police</th>\n",
              "      <th>age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>100798.000000</td>\n",
              "      <td>100798.000000</td>\n",
              "      <td>100798.000000</td>\n",
              "      <td>100780.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2013.000357</td>\n",
              "      <td>6.567601</td>\n",
              "      <td>0.013909</td>\n",
              "      <td>43.857601</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.816278</td>\n",
              "      <td>3.405609</td>\n",
              "      <td>0.117114</td>\n",
              "      <td>19.496181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>2012.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2012.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>27.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2013.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>42.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2014.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>58.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2014.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>107.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                year          month         police            age\n",
              "count  100798.000000  100798.000000  100798.000000  100780.000000\n",
              "mean     2013.000357       6.567601       0.013909      43.857601\n",
              "std         0.816278       3.405609       0.117114      19.496181\n",
              "min      2012.000000       1.000000       0.000000       0.000000\n",
              "25%      2012.000000       4.000000       0.000000      27.000000\n",
              "50%      2013.000000       7.000000       0.000000      42.000000\n",
              "75%      2014.000000       9.000000       0.000000      58.000000\n",
              "max      2014.000000      12.000000       1.000000     107.000000"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get descriptive statistics for the dataset because the dataset contains numerical and categorical variables\n",
        "data.describe()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```markdown\n",
        "The `df.describe()` method in pandas provides a summary of the central tendency, dispersion, and shape of a dataset's distribution, excluding `NaN` values. It generates descriptive statistics for numerical columns by default, including:\n",
        "\n",
        "- **Count**: The number of non-null entries.\n",
        "- **Mean**: The average value.\n",
        "- **Std**: The standard deviation, which measures the spread of the data.\n",
        "- **Min**: The minimum value.\n",
        "- **25%**: The 25th percentile (first quartile).\n",
        "- **50%**: The 50th percentile (median or second quartile).\n",
        "- **75%**: The 75th percentile (third quartile).\n",
        "- **Max**: The maximum value.\n",
        "\n",
        "For example, calling `data.describe()` on our dataset will provide these statistics for columns like `year`, `month`, `age`, etc., helping us understand the distribution and variability of the data.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "year            0\n",
              "month           0\n",
              "intent          1\n",
              "police          0\n",
              "sex             0\n",
              "age            18\n",
              "race            0\n",
              "place        1384\n",
              "education    1422\n",
              "dtype: int64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check for missing values as it may affect the analysis\n",
        "missing_values = data.isnull().sum()\n",
        "missing_values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```markdown\n",
        "The `data.isnull()` method in pandas is used to detect missing values in the DataFrame. It returns a DataFrame of the same shape as `data`, with boolean values indicating whether an element is missing (`True`) or not (`False`). By summing the result with `data.isnull().sum()`, we get the count of missing values for each column.\n",
        "\n",
        "### Findings:\n",
        "- `intent`: 1 missing value\n",
        "- `age`: 18 missing values\n",
        "- `place`: 1,384 missing values\n",
        "- `education`: 1,422 missing values\n",
        "\n",
        "These missing values need to be addressed during data cleaning to ensure accurate analysis.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "39227"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check for duplicate rows in the dataset\n",
        "duplicate_rows = data.duplicated().sum()\n",
        "duplicate_rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "vscode": {
          "languageId": "markdown"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>intent</th>\n",
              "      <th>police</th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>race</th>\n",
              "      <th>place</th>\n",
              "      <th>education</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [year, month, intent, police, sex, age, race, place, education]\n",
              "Index: []"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Calculate the Z-scores for the 'age' column\n",
        "z_scores = stats.zscore(data['age'])\n",
        "\n",
        "# Convert the Z-scores to absolute values\n",
        "abs_z_scores = np.abs(z_scores)\n",
        "\n",
        "# Define a threshold for identifying outliers (e.g., Z-score > 3)\n",
        "threshold = 3\n",
        "\n",
        "# Identify the outliers\n",
        "outliers = data[abs_z_scores > threshold]\n",
        "\n",
        "# Display the outliers\n",
        "outliers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After running a Z test, the outliers detected are in the age section, their are three main ways to address this:\n",
        "\n",
        "1. **Drop the outliers**\n",
        "2. **Keep the outliers**\n",
        "3. **Replace the values with a statistical method using the mean, mode, or median**\n",
        "\n",
        "However, the outliers will be kept, due to the fact that they are real data. The outlier ages are actual ages of victims of dun-related deaths. Another reason is because removing them would askew the resuls, purposely removing real ages of victims due to falling outside the median can be percieved as a form of manipulation of the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Begin Data Cleaning and Refinement\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Drop duplicate rows in the dataset\n",
        "data = data.drop_duplicates()\n",
        "\n",
        "# Check for duplicate rows in the dataset\n",
        "duplicate_rows = data.duplicated().sum()\n",
        "duplicate_rows\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now acting upon the findings found during the data exploration, the duplicated rows have been dropped. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Drop rows with missing values in 'intent' column\n",
        "data = data.dropna(subset=['intent'])\n",
        "\n",
        "# Drop rows with missing values in 'age' column\n",
        "data = data.dropna(subset=['age'])\n",
        "\n",
        "# Drop rows with missing values in 'place' column\n",
        "data = data.dropna(subset=['place'])\n",
        "\n",
        "# Drop rows with missing values in 'education' column\n",
        "data = data.dropna(subset=['education'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Correcting data types\n",
        "data['year'] = data['year'].astype('category')\n",
        "data['month'] = data['month'].astype('category')\n",
        "data['police'] = data['police'].astype('category')\n",
        "data['sex'] = data['sex'].astype('category')\n",
        "data['race'] = data['race'].astype('category')\n",
        "data['place'] = data['place'].astype('category')\n",
        "data['education'] = data['education'].astype('category')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 58927 entries, 0 to 100797\n",
            "Data columns (total 9 columns):\n",
            " #   Column     Non-Null Count  Dtype   \n",
            "---  ------     --------------  -----   \n",
            " 0   year       58927 non-null  category\n",
            " 1   month      58927 non-null  category\n",
            " 2   intent     58927 non-null  object  \n",
            " 3   police     58927 non-null  category\n",
            " 4   sex        58927 non-null  category\n",
            " 5   age        58927 non-null  float64 \n",
            " 6   race       58927 non-null  category\n",
            " 7   place      58927 non-null  category\n",
            " 8   education  58927 non-null  category\n",
            "dtypes: category(7), float64(1), object(1)\n",
            "memory usage: 1.7+ MB\n"
          ]
        }
      ],
      "source": [
        "# Verify the changes\n",
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "year         0\n",
            "month        0\n",
            "intent       0\n",
            "police       0\n",
            "sex          0\n",
            "age          0\n",
            "race         0\n",
            "place        0\n",
            "education    0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Check if data is cleaned\n",
        "missing_values = data.isnull().sum()\n",
        "print (missing_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "markdown"
        }
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Section 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Section 2 content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "NOTE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* You may add as many sections as you want, as long as it supports your project workflow.\n",
        "* All notebook's cells should be run top-down (you can't create a dynamic wherein a given point you need to go back to a previous cell to execute some task, like go back to a previous cell and refresh a variable content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Push files to Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* In cases where you don't need to push files to Repo, you may replace this section with \"Conclusions and Next Steps\" and state your conclusions and next steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "aKlnIozA4eQO",
        "outputId": "fd09bc1f-adb1-4511-f6ce-492a6af570c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WinError 183] Cannot create a file when that file already exists: 'c:\\\\Users\\\\Compu\\\\Crime-Data\\\\new_folder'\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "try:\n",
        "  # Create a new folder in the current directory\n",
        "  os.makedirs(os.path.join(current_dir, 'new_folder'))\n",
        "except Exception as e:\n",
        "  print(e)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
